### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)


### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `WhileLoopInvariantCodeMotion` in TensorFlow XLA.

# Description
The model should contain a while loop where certain instructions within the loop body are invariant, meaning they produce the same result in every iteration of the loop. The `WhileLoopInvariantCodeMotion` optimization pass is triggered when it identifies such invariant instructions that can be hoisted out of the loop, thereby reducing the computational overhead within the loop.

The characteristics of the model that trigger this optimization include:

1. The model contains a while loop.
2. The while loop has a tuple shape.
3. The while loop body contains instructions that are invariant. These instructions do not have side effects, are not parameters, and do not have control predecessors or successors.
4. The operands of these invariant instructions are also invariant or are constants.
5. The invariant instructions are worth hoisting, as determined by the `NotWorthHoistingIndividually` function. This function checks the opcode of the instruction and returns true if the opcode is not in a specific set (e.g., `kConstant`, `kReshape`, `kBitcast`, `kBroadcast`, `kIota`, `kReverse`, `kSlice`, `kTranspose`, `kTuple`).
6. The hoisting of the invariant instruction does not cause a significant memory blow-up, as determined by the `hoist_size_inflation_ratio_` check.

Here is an illustrative example:

```python
def loop_body(x):
    y = tf.constant(5)  # This is an invariant instruction.
    z = tf.add(x, y)
    return z

x = tf.constant(0)
result = tf.while_loop(lambda x: tf.less(x, 10), loop_body, [x])
```

In this example, the constant `y` is an invariant within the loop body and can be hoisted out of the loop by the `WhileLoopInvariantCodeMotion` optimization pass.

# Model