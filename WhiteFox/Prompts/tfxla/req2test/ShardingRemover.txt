### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ReshapeReshapeForwarding` in TensorFlow XLA.

# Description
The model should contain the following pattern:
```
t1 = tf.reshape(input_tensor, ...)
t2 = tf.reshape(t1, input_tensor.shape)
```
The pattern describes that there are two reshape operators in the model. The first `reshape` operator transforms a tensor input `input_tensor` from `input_tensor.shape` to any new shape, and the second `reshape` operator transforms the output of first `reshape` back to `input_tensor.shape`.


# Model
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.reshape(x1, [2,2])
    return tf.reshape(x2, [4])

# Initializing the model
m = Model()

# Inputs to the model
input_shape = [4]
x1 = tf.constant([4.,5.,6.,7.], shape=input_shape)

# Call model
y = m(x1)


### Please generate one valid TensorFlow model that satisfies requirements below.
You should only use public TensorFlow APIs. The model can be used as the input to trigger the optimization pass `ShardingRemover` in TensorFlow XLA.

# Description
The model should contain a custom-call instruction that is one of the following types: "Sharding", "SPMDShardToFullShape", or "SPMDFullToShardShape". These instructions are used for sharding operations in distributed computing. The custom-call instruction should have exactly one operand.

Here is an example of such a pattern in TensorFlow:

```python
# Assume `input_tensor` is a tensor that needs to be sharded
sharding = tf.raw_ops.Sharding(input=input_tensor)
```

In this case, the `ShardingRemover` optimization pass will be triggered, and it will replace all uses of the `sharding` instruction with its operand, effectively removing the sharding operation.

# Model