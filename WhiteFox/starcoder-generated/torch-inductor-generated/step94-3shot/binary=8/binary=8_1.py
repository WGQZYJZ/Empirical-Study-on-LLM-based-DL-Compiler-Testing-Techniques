
class Model(torch.nn.Module):
    def __init__(self, N, M):
        super().__init__()
        self.conv1 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv2 = torch.nn.Conv2d(3, 8, 1, stride=2, padding=1)
        self.conv3 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv4 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv5 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv6 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv7 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv8 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv9 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv10 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv11 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv12 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv13 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv14 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.conv15 = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
        self.convs = torch.nn.ModuleList()
        for i in range(N + M):
            self.convs.append(torch.nn.Conv2d(8, 8,(1,i), stride=1, padding=(0,i%M)))
        self.fc = torch.nn.Linear(8, 64)
        self.bn1 = torch.nn.BatchNorm2d(8)
        self.bn2 = torch.nn.BatchNorm2d(8)
        self.bn3 = torch.nn.BatchNorm2d(8)
        self.bn4 = torch.nn.BatchNorm2d(8)
        self.bn5 = torch.nn.BatchNorm2d(8)
        self.conv16 = torch.nn.Conv2d(8, 8, (1,1), stride=1, padding=0)
        self.bn6 = torch.nn.BatchNorm2d(8)
        self.bn7 = torch.nn.BatchNorm2d(8)
        self.bn8 = torch.nn.BatchNorm2d(8)
        self.bn9 = torch.nn.BatchNorm2d(8)
        self.bn10 = torch.nn.BatchNorm2d(8)
        self.bn11 = torch.nn.BatchNorm2d(8)
        self.bn12 = torch.nn.BatchNorm2d(8)
    def forward(self, x1, x2):
        v1 = self.conv1(x1)
        v2 = self.conv2(x1)
        v3 = self.conv3(x2)
        v4 = self.conv4(x2)
        v5 = self.conv5(x2)
        v6 = self.conv6(x2)
        v7 = self.conv7(x2)
        v8 = self.conv12(x2)
        v9 = torch.nn.functional.pad(v8, (0,0,8,8,0,0))
        v10 = v7 + v9
        v11 = self.conv8(x2)
        v12 = torch.nn.functional.pad(v11, (0,0,8,8,0,0))
        v13 = v6 + v12
        v14 = self.conv9(x2)
        v15 = torch.nn.functional.pad(v14, (0,0,8,8,0,0))
        v16 = v5 + v15
        v17 = self.conv10(x2)
        v18 = torch.nn.functional.pad(v17, (0,0,8,8,0,0))
        v19 = v4 + v18
        v20 = self.conv11(x2)
        v21 = torch.nn.functional.pad(v20, (0,0,8,8,0,0))
        v22 = v3 + v21
        v23 = torch.cat((v16, v22), 1)
        v24 = torch.nn.functional.pad(v23, (8,8,0,0,0,0))
        v25 = v2 + v24
        v26 = torch.nn.functional.pad(v25, (0,0,8,8,0,0))
        v27 = v1 + v26
        v28 = self.conv13(x2)
        v29 = torch.nn.functional.pad(v28, (23,23,0,0,0,0))
        v30 = self.conv14(x2)
        v31 = torch.nn.functional.pad(v30, (16,16,0,0,0,0))
        v32 = self.conv15(x2)
        v33 = torch.nn.functional.pad(v32, (8,8,0,0,0,0))
        v34 = v29 + v31 + v33
        v35 = self.bn1(v27)
        v36 = self.bn2(v34)
        v37 = torch.nn.functional.relu(v36)
        v38 = self.bn3(v37)
        v39 = self.conv16(v38)
        v40 = self.bn4(v39)
        v41 = self.bn5(v40)
        v42 = self.bn6(v41)
        v43 = self.bn7(v42)
        v44 = self.bn8(v43)
        v45 = torch.nn.functional.relu(v44)
        v46 = self.fc(v45)
        v47 = torch.unsqueeze(v46, 0)
        return v47
# Inputs to the model
x1 = torch.randn(1, 3, 8, 10)
x2 = torch.randn(1, 3, 8, 10)
